{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQbcdt2DsE_g"
      },
      "source": [
        "# Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rSRckwUr831",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7febc208-e6a3-465a-c167-4aad32893fbf"
      },
      "source": [
        "!pip install -U PyYAML\n",
        "import yaml\n",
        "print(\"This should be > 5.0 \", yaml.__version__)\n",
        "!git clone https://github.com/rahulanand16nov/Samsung-PRISM\n",
        "!cp -r Samsung-PRISM/* .\n",
        "!rm Model.ipynb*\n",
        "!rm -rf Samsung-PRISM"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (5.4.1)\n",
            "This should be > 5.0  5.4.1\n",
            "Cloning into 'Samsung-PRISM'...\n",
            "remote: Enumerating objects: 35, done.\u001b[K\n",
            "remote: Counting objects: 100% (35/35), done.\u001b[K\n",
            "remote: Compressing objects: 100% (28/28), done.\u001b[K\n",
            "remote: Total 35 (delta 1), reused 32 (delta 1), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (35/35), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZkW2uKwIgsa"
      },
      "source": [
        "# Download dataset and create the image list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhWmwwljDX-7"
      },
      "source": [
        "from pathlib import Path\n",
        "my_file = Path(\"/content/CelebAMask-HQ.zip\")\n",
        "\n",
        "if not my_file.is_file():\n",
        "  !gdown --id 1cDM_RMNrK9CeCn6qmDilu6u-AP2A9Qzs\n",
        "\n",
        "!unzip \"/content/CelebAMask-HQ.zip\" -d \"/content/datasets/celeba-hq/\"\n",
        "!rm /content/CelebAMask-HQ.zip\n",
        "\n",
        "\n",
        "\n",
        "import os\n",
        "import argparse\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--path', type=str, help='../datasets/celeba-hq/CelebAMask-HQ/CelebAMask-HQ-img/')\n",
        "parser.add_argument('--output', type=str, help='../datasets/celeba-hq/list_val.txt')\n",
        "args = parser.parse_args()\n",
        "\n",
        "ext = {'.jpg', '.png', '.JPG'}\n",
        "\n",
        "images = []\n",
        "for root, dirs, files in os.walk(args.path):\n",
        "    print('loading ' + root)\n",
        "    for file in files:\n",
        "        if os.path.splitext(file)[1] in ext:\n",
        "            images.append(os.path.join(root, file))\n",
        "images = sorted(images)\n",
        "np.savetxt(args.output, images, fmt='%s')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFCQE_mwmkdQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 744
        },
        "outputId": "53c3a0a3-6512-4d3c-d2ed-e727e651e49b"
      },
      "source": [
        "import argparse\n",
        "import os\n",
        "from utils import get_config, _write_images\n",
        "import torch\n",
        "from data import create_dataset, create_dataloader\n",
        "from models.networks import define_G\n",
        "from data.util import tensor2img\n",
        "import skimage.io as sio\n",
        "import numpy as np\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--config', type=str, default='configs/celeba-hq-regular_list.yaml', help=\"net configuration\")\n",
        "parser.add_argument('--output_folder', type=str, default='outputs/celebahq-regular/saved_images', help=\"output image path\")\n",
        "parser.add_argument('--checkpoint', type=str, default='outputs/celebahq-regular/checkpoints/latest_G.pth',\n",
        "                    help=\"checkpoint of generator\")\n",
        "opts = parser.parse_args(args=[])\n",
        "\n",
        "if not os.path.exists(opts.output_folder):\n",
        "    os.makedirs(opts.output_folder)\n",
        "\n",
        "# Load experiment setting\n",
        "config = get_config(opts.config)\n",
        "\n",
        "device = torch.device('cuda')\n",
        "# Setup model and data loader\n",
        "\n",
        "\n",
        "model = define_G(config).to(device)\n",
        "model.load_state_dict(torch.load(opts.checkpoint), strict=True)\n",
        "model.eval()\n",
        "\n",
        "print('Loading the checkpoint for G [{:s}] ...'.format(opts.checkpoint))\n",
        "\n",
        "with torch.no_grad():\n",
        "    dataset_opt = config['datasets']['test']\n",
        "    test_set = create_dataset(dataset_opt)\n",
        "    test_loader = create_dataloader(test_set, dataset_opt)\n",
        "    print('Number of test images in [{:s}]: {:d}'.format(dataset_opt['name'], len(test_set)))\n",
        "\n",
        "    # Start testing\n",
        "\n",
        "    for index, test_data in enumerate(test_loader):\n",
        "        v_input, v_output, v_target = [], [], []\n",
        "        visual_images = []\n",
        "        var_input, var_mask, var_target, img_paths = test_data['input'], test_data['mask'], test_data['target'], \\\n",
        "                                                     test_data['paths']\n",
        "        var_input = var_input.to(device)\n",
        "        var_mask = var_mask.to(device)\n",
        "        var_target = var_target.to(device)\n",
        "        var_output = var_mask.detach() * model(torch.cat([var_input, var_mask], dim=1)) + (\n",
        "                1 - var_mask.detach()) * var_input.detach()\n",
        "        v_input.append(var_input.detach()[0].float().cpu())\n",
        "        v_output.append(var_output.detach()[0].float().cpu())\n",
        "        v_target.append(var_target.detach()[0].float().cpu())\n",
        "        visual_images.extend(v_input)\n",
        "        visual_images.extend(v_output)\n",
        "        visual_images.extend(v_target)\n",
        "        _write_images(visual_images, 1, '%s/%s' % (opts.output_folder, img_paths[0].split('/')[-1]))\n",
        "        saved_mask = (var_mask.detach()[0].float().cpu().numpy().squeeze() * 255).round().astype(np.uint8)\n",
        "        saved_input = (var_mask.detach()[0].float().cpu() + ((v_target[0] + 1) / 2)).numpy().squeeze().transpose(1, 2, 0).clip(0, 1)\n",
        "        saved_output = tensor2img(v_output)\n",
        "        saved_target = tensor2img(v_target)\n",
        "        sio.imsave(os.path.join(opts.output_folder, 'mask', img_paths[0].split('/')[-1].split('.')[0] + '.png'), saved_mask)\n",
        "        sio.imsave(os.path.join(opts.output_folder, 'input', img_paths[0].split('/')[-1]), saved_input)\n",
        "        sio.imsave(os.path.join(opts.output_folder, 'output', img_paths[0].split('/')[-1]), saved_output[0])\n",
        "        sio.imsave(os.path.join(opts.output_folder, 'target', img_paths[0].split('/')[-1]), saved_target[0])\n",
        "\n",
        "\n",
        "print('End of testing.')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading the checkpoint for G [outputs/celebahq-regular/checkpoints/latest_G.pth] ...\n",
            "Number of test images in [celeba-hq]: 2000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-8960da1d01a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# Start testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mv_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mvisual_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1201\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1203\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1227\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1229\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0;31m# have message field\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Caught FileNotFoundError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/content/data/dataset.py\", line 42, in __getitem__\n    img = self.loader(impath)\n  File \"/content/data/dataset.py\", line 11, in default_loader\n    return Image.open(path).convert('RGB')\n  File \"/usr/local/lib/python3.7/dist-packages/PIL/Image.py\", line 2843, in open\n    fp = builtins.open(filename, \"rb\")\nFileNotFoundError: [Errno 2] No such file or directory: '/data/zheng/Celeba-hq_png/celeba_hq_val/img00000003.png'\n"
          ]
        }
      ]
    }
  ]
}