{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQbcdt2DsE_g"
      },
      "source": [
        "# Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rSRckwUr831",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bbd123c-8f9b-413d-83a3-918c1a2d5215"
      },
      "source": [
        "!pip install -U PyYAML\n",
        "import yaml\n",
        "print(\"This should be > 5.0 \", yaml.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (5.4.1)\n",
            "fatal: destination path 'DMFN' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFCQE_mwmkdQ"
      },
      "source": [
        "import argparse\n",
        "import os\n",
        "from utils import get_config, _write_images\n",
        "import torch\n",
        "from data import create_dataset, create_dataloader\n",
        "from models.networks import define_G\n",
        "from data.util import tensor2img\n",
        "import skimage.io as sio\n",
        "import numpy as np\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--config', type=str, default='configs/celeba-hq-regular_list.yaml', help=\"net configuration\")\n",
        "parser.add_argument('--output_folder', type=str, default='outputs/celebahq-regular/saved_images', help=\"output image path\")\n",
        "parser.add_argument('--checkpoint', type=str, default='outputs/celebahq-regular/checkpoints/latest_G.pth',\n",
        "                    help=\"checkpoint of generator\")\n",
        "opts = parser.parse_args(args=[])\n",
        "\n",
        "if not os.path.exists(opts.output_folder):\n",
        "    os.makedirs(opts.output_folder)\n",
        "\n",
        "# Load experiment setting\n",
        "config = get_config(opts.config)\n",
        "\n",
        "device = torch.device('cuda')\n",
        "# Setup model and data loader\n",
        "\n",
        "\n",
        "model = define_G(config).to(device)\n",
        "model.load_state_dict(torch.load(opts.checkpoint), strict=True)\n",
        "model.eval()\n",
        "\n",
        "print('Loading the checkpoint for G [{:s}] ...'.format(opts.checkpoint))\n",
        "\n",
        "with torch.no_grad():\n",
        "    dataset_opt = config['datasets']['test']\n",
        "    test_set = create_dataset(dataset_opt)\n",
        "    test_loader = create_dataloader(test_set, dataset_opt)\n",
        "    print('Number of test images in [{:s}]: {:d}'.format(dataset_opt['name'], len(test_set)))\n",
        "\n",
        "    # Start testing\n",
        "\n",
        "    for index, test_data in enumerate(test_loader):\n",
        "        v_input, v_output, v_target = [], [], []\n",
        "        visual_images = []\n",
        "        var_input, var_mask, var_target, img_paths = test_data['input'], test_data['mask'], test_data['target'], \\\n",
        "                                                     test_data['paths']\n",
        "        var_input = var_input.to(device)\n",
        "        var_mask = var_mask.to(device)\n",
        "        var_target = var_target.to(device)\n",
        "        var_output = var_mask.detach() * model(torch.cat([var_input, var_mask], dim=1)) + (\n",
        "                1 - var_mask.detach()) * var_input.detach()\n",
        "        v_input.append(var_input.detach()[0].float().cpu())\n",
        "        v_output.append(var_output.detach()[0].float().cpu())\n",
        "        v_target.append(var_target.detach()[0].float().cpu())\n",
        "        visual_images.extend(v_input)\n",
        "        visual_images.extend(v_output)\n",
        "        visual_images.extend(v_target)\n",
        "        _write_images(visual_images, 1, '%s/%s' % (opts.output_folder, img_paths[0].split('/')[-1]))\n",
        "        saved_mask = (var_mask.detach()[0].float().cpu().numpy().squeeze() * 255).round().astype(np.uint8)\n",
        "        saved_input = (var_mask.detach()[0].float().cpu() + ((v_target[0] + 1) / 2)).numpy().squeeze().transpose(1, 2, 0).clip(0, 1)\n",
        "        saved_output = tensor2img(v_output)\n",
        "        saved_target = tensor2img(v_target)\n",
        "        sio.imsave(os.path.join(opts.output_folder, 'mask', img_paths[0].split('/')[-1].split('.')[0] + '.png'), saved_mask)\n",
        "        sio.imsave(os.path.join(opts.output_folder, 'input', img_paths[0].split('/')[-1]), saved_input)\n",
        "        sio.imsave(os.path.join(opts.output_folder, 'output', img_paths[0].split('/')[-1]), saved_output[0])\n",
        "        sio.imsave(os.path.join(opts.output_folder, 'target', img_paths[0].split('/')[-1]), saved_target[0])\n",
        "\n",
        "\n",
        "print('End of testing.')\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}